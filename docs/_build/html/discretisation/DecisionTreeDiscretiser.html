

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DecisionTreeDiscretiser &mdash; fast_feature 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GeometricWidthDiscretiser" href="GeometricWidthDiscretiser.html" />
    <link rel="prev" title="ArbitraryDiscretiser" href="ArbitraryDiscretiser.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            fast_feature
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../encoding/index.html">Categorical Encoding</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Discretisation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="EqualFrequencyDiscretiser.html">EqualFrequencyDiscretiser</a></li>
<li class="toctree-l2"><a class="reference internal" href="EqualWidthDiscretiser.html">EqualWidthDiscretiser</a></li>
<li class="toctree-l2"><a class="reference internal" href="ArbitraryDiscretiser.html">ArbitraryDiscretiser</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">DecisionTreeDiscretiser</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fast_feature.discretisation.DecisionTreeDiscretiser"><code class="docutils literal notranslate"><span class="pre">DecisionTreeDiscretiser</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#fast_feature.discretisation.DecisionTreeDiscretiser.fit"><code class="docutils literal notranslate"><span class="pre">DecisionTreeDiscretiser.fit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#fast_feature.discretisation.DecisionTreeDiscretiser.transform"><code class="docutils literal notranslate"><span class="pre">DecisionTreeDiscretiser.transform()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="GeometricWidthDiscretiser.html">GeometricWidthDiscretiser</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#additional-transformers-for-discretisation">Additional transformers for discretisation</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../wrappers/index.html">Scikit-learn Wrapper</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../datasets/index.html">Datasets</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../variable_handling/index.html">Variable handling functions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">fast_feature</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Discretisation</a></li>
      <li class="breadcrumb-item active">DecisionTreeDiscretiser</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/discretisation/DecisionTreeDiscretiser.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="decisiontreediscretiser">
<h1>DecisionTreeDiscretiser<a class="headerlink" href="#decisiontreediscretiser" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="fast_feature.discretisation.DecisionTreeDiscretiser">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">fast_feature.discretisation.</span></span><span class="sig-name descname"><span class="pre">DecisionTreeDiscretiser</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variables</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bin_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'prediction'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precision</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'neg_mean_squared_error'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regression</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#fast_feature.discretisation.DecisionTreeDiscretiser" title="Link to this definition"></a></dt>
<dd><p>The DecisionTreeDiscretiser() replaces numerical variables by discrete, i.e.,
finite variables, whose values are the predictions of a decision tree, the  bin
number, or the bin limits.</p>
<p>The method is inspired by the following article from the winners of the KDD
2009 competition:
<a class="reference external" href="http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf">http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf</a></p>
<p>The DecisionTreeDiscretiser() trains a decision tree per variable. Then it finds
the boundaries of each bin. Finally, it replaces the variable values with
the predictions of the decision tree, the bin number, or the bin limits.</p>
<p>The DecisionTreeDiscretiser() works only with numerical variables. You can pass a
list with the variables you wish to transform. Alternatively, the discretiser will
automatically select all numerical variables.</p>
<p>More details in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>variables: list, default=None</strong></dt><dd><p>The list of numerical variables to transform. If None, the transformer will
automatically find and select all numerical variables.</p>
</dd>
<dt><strong>bin_output: str, default = “prediction”</strong></dt><dd><p>Whether to return the predictions of the tree, the bin number, or the interval
boundaries. Takes values “prediction”, “bin_number” and “boundaries”,
respectively.</p>
</dd>
<dt><strong>precision: int, default=None</strong></dt><dd><p>The precision at which to store and display the bins labels. In other words,
the number of decimals after the comma. Only used when <code class="docutils literal notranslate"><span class="pre">bin_output</span></code> is
“prediction” or “boundaries”. If <code class="docutils literal notranslate"><span class="pre">bin_output=&quot;boundaries&quot;</span></code> then precision
cannot be None.</p>
</dd>
<dt><strong>cv: int, cross-validation generator or an iterable, default=3</strong></dt><dd><p>Determines the cross-validation splitting strategy. Possible inputs for cv are:</p>
<blockquote>
<div><ul class="simple">
<li><p>None, to use cross_validate’s default 5-fold cross validation</p></li>
<li><p>int, to specify the number of folds in a (Stratified)KFold,</p></li>
<li><dl class="simple">
<dt>CV splitter</dt><dd><ul>
<li><p>(<a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-CV-splitter">https://scikit-learn.org/stable/glossary.html#term-CV-splitter</a>)</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
</div></blockquote>
<p>For int/None inputs, if the estimator is a classifier and y is either binary or
multiclass, StratifiedKFold is used. In all other cases, KFold is used. These
splitters are instantiated with <code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code> so the splits will be the same
across calls. For more details check Scikit-learn’s <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>’s
documentation.</p>
</dd>
<dt><strong>scoring: str, default=’neg_mean_squared_error’</strong></dt><dd><p>Desired metric to optimise the performance of the tree. Comes from
sklearn.metrics. See the DecisionTreeRegressor or DecisionTreeClassifier
model evaluation documentation for more options:
<a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html">https://scikit-learn.org/stable/modules/model_evaluation.html</a></p>
</dd>
<dt><strong>param_grid: dictionary, default=None</strong></dt><dd><p>The hyperparameters for the decision tree to test with a grid search. The
<code class="docutils literal notranslate"><span class="pre">param_grid</span></code> can contain any of the permitted hyperparameters for Scikit-learn’s
DecisionTreeRegressor() or DecisionTreeClassifier(). If None, then param_grid
will optimise the ‘max_depth’ over <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4]</span></code>.</p>
</dd>
<dt><strong>regression: boolean, default=True</strong></dt><dd><p>Indicates whether the discretiser should train a regression or a classification
decision tree.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, default=None</span></dt><dd><p>The random_state to initialise the training of the decision tree. It is one
of the parameters of the Scikit-learn’s DecisionTreeRegressor() or
DecisionTreeClassifier(). For reproducibility it is recommended to set
the random_state to an integer.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>binner_dict_:</strong></dt><dd><p>Dictionary with the interval limits per variable or the fitted tree per
variable, depending on how <code class="docutils literal notranslate"><span class="pre">bin_output</span></code> was set up.</p>
</dd>
<dt><strong>scores_dict_:</strong></dt><dd><p>Dictionary with the score of the best decision tree per variable.</p>
</dd>
<dt><strong>variables_:</strong></dt><dd><p>The group of variables that will be transformed.</p>
</dd>
<dt><strong>feature_names_in_:</strong></dt><dd><p>List with the names of features seen during <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>n_features_in_:</strong></dt><dd><p>The number of features in the train set used in fit.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><strong>fit:</strong></p></td>
<td><p>Fit a decision tree per variable and find the interval limits.</p></td>
</tr>
<tr class="row-even"><td><p><strong>fit_transform:</strong></p></td>
<td><p>Fit to data, then transform it.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>get_feature_names_out:</strong></p></td>
<td><p>Get output feature names for transformation.</p></td>
</tr>
<tr class="row-even"><td><p><strong>get_params:</strong></p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>set_params:</strong></p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><strong>transform:</strong></p></td>
<td><p>Sort continuous variables into intervals or replace them with the predictions.</p></td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.tree.DecisionTreeClassifier</span></code></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.tree.DecisionTreeRegressor</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r59c0c2dbe3c3-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Niculescu-Mizil, et al. “Winning the KDD Cup Orange Challenge with Ensemble
Selection”. JMLR: Workshop and Conference Proceedings 7: 23-34. KDD 2009
<a class="reference external" href="http://proceedings.mlr.press/v7/niculescu09/niculescu09.pdf">http://proceedings.mlr.press/v7/niculescu09/niculescu09.pdf</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">fast_feature.discretisation</span> <span class="kn">import</span> <span class="n">DecisionTreeDiscretiser</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_reg</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dtd</span> <span class="o">=</span> <span class="n">DecisionTreeDiscretiser</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dtd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_reg</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dtd</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="go">-0.090091    90</span>
<span class="go">0.479454    10</span>
<span class="go">Name: x, dtype: int64</span>
</pre></div>
</div>
<p>You can also apply this for classification problems adjusting the scoring metric.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_clf</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dtd</span> <span class="o">=</span> <span class="n">DecisionTreeDiscretiser</span><span class="p">(</span><span class="n">regression</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dtd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_clf</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dtd</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="go">0.480769    52</span>
<span class="go">0.687500    48</span>
<span class="go">Name: x, dtype: int64</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="fast_feature.discretisation.DecisionTreeDiscretiser.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#fast_feature.discretisation.DecisionTreeDiscretiser.fit" title="Link to this definition"></a></dt>
<dd><p>Fit one decision tree per variable to discretize with cross-validation and
grid-search for hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X: polars or pandas dataframe of shape = [n_samples, n_features]</strong></dt><dd><p>The training dataset. Can be the entire dataframe, not just the
variables to be transformed.</p>
</dd>
<dt><strong>y: pandas series.</strong></dt><dd><p>Target variable. Required to train the decision tree.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="fast_feature.discretisation.DecisionTreeDiscretiser.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#fast_feature.discretisation.DecisionTreeDiscretiser.transform" title="Link to this definition"></a></dt>
<dd><p>Replaces original variable values with the predictions of the tree. The
decision tree predictions are finite, aka, discrete.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X: polars or pandas dataframe of shape = [n_samples, n_features]</strong></dt><dd><p>The input samples.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>X_new: polars or pandas dataframe of shape = [n_samples, n_features]</dt><dd><p>The dataframe with transformed variables.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ArbitraryDiscretiser.html" class="btn btn-neutral float-left" title="ArbitraryDiscretiser" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="GeometricWidthDiscretiser.html" class="btn btn-neutral float-right" title="GeometricWidthDiscretiser" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Ahmad Zaenal.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>